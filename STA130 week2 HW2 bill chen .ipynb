{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07936b9a",
   "metadata": {},
   "source": [
    "#### 1. Begin (or restart) part \"3(a)\" of the **TUT Demo** and interact with a ChatBot to make sure you understand how each part the Monte Hall problem code above works<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c630225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "This Monte Hall simulation code is a good example of how to implement the Monty Hall problem using Python. Here’s a step-by-step breakdown of how it works:\n",
    "\n",
    "Initialization:\n",
    "\n",
    "all_door_options is a tuple representing the three doors (1, 2, 3).\n",
    "my_door_choice is initially set to 1, representing the contestant's choice.\n",
    "i_won keeps track of the number of times the contestant wins.\n",
    "reps is the number of simulations to run.\n",
    "Simulation Loop:\n",
    "\n",
    "For each iteration (total reps times):\n",
    "secret_winning_door is randomly chosen from all_door_options to represent the door with the prize.\n",
    "all_door_options_list is created from all_door_options to manipulate the options.\n",
    "The secret_winning_door is removed from the list to avoid showing it as a losing door.\n",
    "If my_door_choice is not the secret_winning_door, it is also removed from the list.\n",
    "A losing door (goat) is randomly chosen from the remaining doors and removed from the list.\n",
    "If the secret_winning_door was not my_door_choice, it is added back to the list (as it's the only door left).\n",
    "The contestant then swaps their choice to the remaining door in the list.\n",
    "If the contestant's final choice matches the secret_winning_door, i_won is incremented.\n",
    "Winning Probability Calculation:\n",
    "\n",
    "After completing all iterations, the winning probability is calculated by dividing the number of wins (i_won) by the total number of simulations (reps).\n",
    "Things to Note:\n",
    "Random Choices: The use of np.random.choice ensures that each door is chosen randomly.\n",
    "Error Handling: The try and except block ensures that if my_door_choice was the same as secret_winning_door, it doesn’t cause an error when trying to remove it from the list.\n",
    "Swap Strategy: The contestant always swaps to the remaining door after a goat door is revealed, simulating the \"swap\" strategy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17300608",
   "metadata": {},
   "source": [
    "#### 2. Extend your ChatBot sessions to now address part \"3(b)\" of the **TUT Demo** and interact with your ChatBot to see if it can suggest a simpler, more streamlined way to code up this *for* loop simulation so the process is more clear and easier to understand; then, describe any preferences you have in terms of readibility or explainability  between the original code and the code improvements suggested by the ChatBot<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615fe126",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Using Enumerate for Tracking Iterations:\n",
    "In the original code, you use for i in range(reps): to loop through the number of repetitions. This is straightforward, but if you ever needed the index alongside values from a list, using enumerate() is more Pythonic and readable.\n",
    "\n",
    "2. Minimizing List Operations:\n",
    "The original code involves creating and manipulating lists multiple times within the loop (e.g., removing elements and adding them back). We can streamline this to make the logic more transparent by keeping only necessary operations.\n",
    "\n",
    "3. Handling Door Choices More Explicitly:\n",
    "Instead of using a try-except block to handle removing the player's choice, we can simplify this by directly controlling the logic.\n",
    "\n",
    "Here is the new code:\n",
    "import numpy as np\n",
    "\n",
    "def monty_hall_simulation(reps):\n",
    "    wins = 0\n",
    "    all_doors = (1, 2, 3)  # Doors 1, 2, 3\n",
    "    \n",
    "    for _ in range(reps):\n",
    "        # Step 1: Randomly assign the car behind one door\n",
    "        winning_door = np.random.choice(all_doors)\n",
    "        \n",
    "        # Step 2: Player picks a random door\n",
    "        player_choice = np.random.choice(all_doors)\n",
    "        \n",
    "        # Step 3: Host reveals a goat door\n",
    "        remaining_doors = [door for door in all_doors if door != player_choice and door != winning_door]\n",
    "        goat_door = np.random.choice(remaining_doors)\n",
    "        \n",
    "        # Step 4: Player switches to the remaining unopened door\n",
    "        switched_choice = [door for door in all_doors if door != player_choice and door != goat_door][0]\n",
    "        \n",
    "        # Step 5: Check if the switched door is the winning door\n",
    "        if switched_choice == winning_door:\n",
    "            wins += 1\n",
    "\n",
    "    # Calculate and return win rate\n",
    "    return wins / reps\n",
    "\n",
    "\n",
    "# Run the simulation for 100,000 trials\n",
    "win_rate = monty_hall_simulation(100000)\n",
    "win_rate\n",
    "\n",
    "Preferences for Readability and Explainability:\n",
    "Original Code: The original code is functional but involves a lot of list manipulation that may obscure the core logic. The try-except block can also make the flow harder to follow.\n",
    "\n",
    "Simplified Code: The streamlined version focuses on keeping the logic direct and easy to follow. It breaks the simulation down into clear, logical steps, making it more transparent for someone reading the code.\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c01a9bc",
   "metadata": {},
   "source": [
    "#### 3. Submit your preferred version of the Monty Hall problem that is verified to be running and working with a final printed output of the code; then, add code comments explaining the purpose of each line of the code<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b215e9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "The code below is my favorate code to solve Monty Hall problem:\n",
    "\n",
    "import numpy as np   \n",
    "\n",
    "def monty_hall_simulation(reps): #define the function--monty_hall_simulation\n",
    "    wins = 0   # The number of the winning situation.\n",
    "    all_doors = (1, 2, 3)  # give the initial example--Doors 1, 2, 3\n",
    "    \n",
    "    for _ in range(reps):\n",
    "        # Step 1: Randomly assign the car behind one door\n",
    "        winning_door = np.random.choice(all_doors)\n",
    "        \n",
    "        # Step 2: Player picks a random door\n",
    "        player_choice = np.random.choice(all_doors)\n",
    "        \n",
    "        # Step 3: Host reveals a goat door\n",
    "        remaining_doors = [door for door in all_doors if door != player_choice and door != winning_door]\n",
    "        goat_door = np.random.choice(remaining_doors)\n",
    "        \n",
    "        # Step 4: Player switches to the remaining unopened door\n",
    "        switched_choice = [door for door in all_doors if door != player_choice and door != goat_door][0]\n",
    "        \n",
    "        # Step 5: Check if the switched door is the winning door\n",
    "        if switched_choice == winning_door:\n",
    "            wins += 1\n",
    "\n",
    "    # Calculate and return win rate\n",
    "    return wins / reps\n",
    "\n",
    "# Run the simulation for 100,000 trials\n",
    "win_rate = monty_hall_simulation(100000)  #suppose that there will exist 10000 situations.\n",
    "win_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29f32f2",
   "metadata": {},
   "source": [
    "#### 4. Watch the embedded video tutorial on Markov chains in the next Jupyter cell below to understand their application and relevance for ChatBots; then, after watching the video, start a new ChatBot session by prompting that you have code that creates a \"Markovian ChatBot\"; show it the first version of the \"Markovian ChatBot code\" below; and interact with the ChatBot session to make sure you understand how the original first version of the \"Markovian ChatBot code\" works<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44da499",
   "metadata": {},
   "outputs": [],
   "source": [
    "First Version of Markovian ChatBot Code:\n",
    "\n",
    "# Markovian Chatbot\n",
    "\n",
    "# from collections import defaultdict\n",
    "word_used = dict() # defaultdict(int)\n",
    "next_word = dict() # defaultdict(lambda: defaultdict(int))\n",
    "for i,word in enumerate(words[:-1]):\n",
    "\n",
    "    if word in word_used:\n",
    "        word_used[word] += 1\n",
    "    else:\n",
    "        word_used[word] = 1\n",
    "        next_word[word] = {}\n",
    "\n",
    "    if words[i+1] in next_word[word]:\n",
    "        next_word[word][words[i+1]] += 1\n",
    "    else:\n",
    "        next_word[word][words[i+1]] = 1\n",
    "        \n",
    "\n",
    "This code snippet is part of a Markovian model that builds a word transition probability matrix from a given list of words. Here's a breakdown of how it works:\n",
    "\n",
    "Initialization:\n",
    "\n",
    "word_used: This dictionary keeps track of the count of each word in the list. It stores the number of times each word appears.\n",
    "next_word: This dictionary keeps track of the word that follows each word and the count of occurrences of those following words.\n",
    "Iterating Through Words:\n",
    "\n",
    "for i, word in enumerate(words[:-1]): This loop iterates over the list of words, but stops at the second-to-last word (words[:-1]). The reason for stopping at words[:-1] is that the loop will look at each word and the word that follows it.\n",
    "Updating Word Count:\n",
    "\n",
    "if word in word_used: Checks if the current word has been encountered before.\n",
    "word_used[word] += 1: If the word is already in word_used, increment its count.\n",
    "else: If the word is not in word_used, add it to the dictionary with an initial count of 1 and initialize an empty dictionary for the following words.\n",
    "Updating Following Word Counts:\n",
    "\n",
    "if words[i+1] in next_word[word]: Checks if the word following the current word is already in the dictionary for the current word.\n",
    "next_word[word][words[i+1]] += 1: If it is, increment the count for that following word.\n",
    "else: If the following word is not in the dictionary, add it with an initial count of 1.\n",
    "Example\n",
    "Consider the following list of words:\n",
    "\n",
    "\n",
    "words = [\"I\", \"love\", \"Python\", \"and\", \"I\", \"love\", \"coding\"]\n",
    "After running this code:\n",
    "\n",
    "word_used will be:\n",
    "\n",
    "{\"I\": 2, \"love\": 2, \"Python\": 1, \"and\": 1, \"coding\": 1}\n",
    "next_word will be:\n",
    "\n",
    "{\n",
    "    \"I\": {\"love\": 2},\n",
    "    \"love\": {\"Python\": 1, \"coding\": 1},\n",
    "    \"Python\": {\"and\": 1},\n",
    "    \"and\": {\"I\": 1}\n",
    "}\n",
    "Summary\n",
    "This code constructs a dictionary where each word maps to a dictionary of subsequent words and their occurrence counts. This can be useful for generating text based on word probabilities, \n",
    "where the likelihood of a word following another is based on historical data.\n",
    "\n",
    "\n",
    "The applications of markov chain:\n",
    "    Physics\n",
    "Markovian systems appear extensively in thermodynamics and statistical mechanics, whenever probabilities are used to represent unknown or unmodelled details of the system, if it can be assumed that the dynamics are time-invariant, and that no relevant history need be considered which is not already included in the state description.[60][61] For example, a thermodynamic state operates under a probability distribution that is difficult or expensive to acquire. Therefore, Markov Chain Monte Carlo method can be used to draw samples randomly from a black-box to approximate the probability distribution of attributes over a range of objects.[61]\n",
    "\n",
    "Markov chains are used in lattice QCD simulations.[62]\n",
    "\n",
    "Chemistry:\n",
    "\n",
    "Michaelis-Menten kinetics. The enzyme (E) binds a substrate (S) and produces a product (P). Each reaction is a state transition in a Markov chain.\n",
    "A reaction network is a chemical system involving multiple reactions and chemical species. The simplest stochastic models of such networks treat the system as a continuous time Markov chain with the state being the number of molecules of each species and with reactions modeled as possible transitions of the chain.[63] Markov chains and continuous-time Markov processes are useful in chemistry when physical systems closely approximate the Markov property. For example, imagine a large number n of molecules in solution in state A, each of which can undergo a chemical reaction to state B with a certain average rate. Perhaps the molecule is an enzyme, and the states refer to how it is folded. The state of any single enzyme follows a Markov chain, and since the molecules are essentially independent of each other, the number of molecules in state A or B at a time is n times the probability a given molecule is in that state.\n",
    "\n",
    "The classical model of enzyme activity, Michaelis–Menten kinetics, can be viewed as a Markov chain, where at each time step the reaction proceeds in some direction. While Michaelis-Menten is fairly straightforward, far more complicated reaction networks can also be modeled with Markov chains.[64]\n",
    "\n",
    "An algorithm based on a Markov chain was also used to focus the fragment-based growth of chemicals in silico towards a desired class of compounds such as drugs or natural products.[65] As a molecule is grown, a fragment is selected from the nascent molecule as the \"current\" state. It is not aware of its past (that is, it is not aware of what is already bonded to it). It then transitions to the next state when a fragment is attached to it. The transition probabilities are trained on databases of authentic classes of compounds.[66]\n",
    "\n",
    "Also, the growth (and composition) of copolymers may be modeled using Markov chains. Based on the reactivity ratios of the monomers that make up the growing polymer chain, the chain's composition may be calculated (for example, whether monomers tend to add in alternating fashion or in long runs of the same monomer). Due to steric effects, second-order Markov effects may also play a role in the growth of some polymer chains.\n",
    "\n",
    "Similarly, it has been suggested that the crystallization and growth of some epitaxial superlattice oxide materials can be accurately described by Markov chains.[67]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30054547",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/66e5c3b6-bc10-8003-90a9-0aed5e75c806\n",
    "this is the link of chatbot website that I have used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f5d11",
   "metadata": {},
   "source": [
    "#### 5. Recreate (or resume) the previous ChatBot session from question \"4\" above, and now  prompt the ChatBot session that you have a couple extensions of the code to show it, and then show it each of the extentions of the \"Markovian ChatBot code\" below in turn\n",
    "\n",
    "\n",
    "\n",
    "1. Without just supplying your ChatBot session with the answers, see if the ChatBot can figure out what the extensions in the code do; namely, making character specific Markov chains, and using bigrams (rather than just the previous word alone) dependency... prompt your ChatBot session with some hints if it's not seeming to \"get it\"<br><br>\n",
    "    \n",
    "2. Interact with your ChatBot session to have it explain details of the code wherever you need help understanding what the code is doing and how it works<br><br>\n",
    "    \n",
    "3. Start yet another new ChatBot session and first show the ChatBot the original \"Markovian ChatBot code\" below, and then tell ChatBot that you have an extension but this time just directly provide it the more complicated final extension without ever providing the intermediate extension code to the ChatBot session and see if it's still able to understand everything extension does; namely, making character specific Markov chains, and using bigrams (rather than just the previous word alone) dependency... prompt the ChatBot with some hints if it's not seeming to understand what you're getting at...<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ea9c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "5.1\n",
    "This extended version of the Markovian chatbot code creates a model that captures the probability of a word sequence of length 2 (bigrams) transitioning to a third word (trigrams). Here’s how it works:\n",
    "\n",
    "Initialization:\n",
    "\n",
    "word_used2: A defaultdict of int that keeps track of the count of each bigram (a pair of consecutive words).\n",
    "next_word2: A defaultdict of defaultdict(int) that tracks the counts of the third word following a given bigram.\n",
    "Iterating Through Words:\n",
    "\n",
    "for i, word in enumerate(words[:-2]): This loop iterates through the list of words but stops at the third-to-last word (words[:-2]). This is necessary because each iteration considers a bigram (words[i] and words[i+1]) and needs to look ahead two more words (words[i+2]).\n",
    "Updating Bigram Counts:\n",
    "\n",
    "word_used2[word+' '+words[i+1]] += 1: Creates a bigram by concatenating the current word and the next word (word + ' ' + words[i+1]). It increments the count for this bigram in word_used2.\n",
    "Updating Following Word Counts:\n",
    "\n",
    "next_word2[word+' '+words[i+1]][words[i+2]] += 1: For the bigram, updates the count of the third word (words[i+2]) in next_word2. This keeps track of how often a specific word follows the given bigram.\n",
    "Example\n",
    "Given a list of words:\n",
    "\n",
    "words = [\"I\", \"love\", \"Python\", \"and\", \"I\", \"love\", \"coding\"]\n",
    "After running this code:\n",
    "\n",
    "word_used2 will be:\n",
    "\n",
    "{\n",
    "    \"I love\": 2,\n",
    "    \"love Python\": 1,\n",
    "    \"Python and\": 1,\n",
    "    \"and I\": 1,\n",
    "    \"I love\": 1,\n",
    "    \"love coding\": 1\n",
    "}\n",
    "next_word2 will be:\n",
    "\n",
    "{\n",
    "    \"I love\": {\"Python\": 1, \"coding\": 1},\n",
    "    \"love Python\": {\"and\": 1},\n",
    "    \"Python and\": {\"I\": 1},\n",
    "    \"and I\": {\"love\": 1},\n",
    "    \"I love\": {\"coding\": 1}\n",
    "}\n",
    "Summary\n",
    "This extension captures not just the transitions between individual words but the transitions between pairs of words (bigrams) to a third word (trigrams). This allows the model to understand and generate more complex patterns of word sequences,\n",
    "which can lead to more coherent and contextually appropriate responses in a chatbot scenario.\n",
    "\n",
    "5.2\n",
    "\n",
    "import random\n",
    "import string\n",
    "from collections import defaultdict\n",
    "\n",
    "# Step 1: Collecting and preparing the text data\n",
    "# Tokenizer that removes punctuation and converts text to lowercase\n",
    "def tokenize(text):\n",
    "    # Remove punctuation using str.translate and convert to lowercase\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    return text.split()\n",
    "\n",
    "# Step 2: Building the Markov chain model\n",
    "# Option 1: Standard Markov Chain (Unigrams)\n",
    "def build_markov_chain(tokens):\n",
    "    markov_chain = {}\n",
    "    \n",
    "    for i in range(len(tokens) - 1):\n",
    "        current_word = tokens[i]\n",
    "        next_word = tokens[i + 1]\n",
    "        \n",
    "        if current_word not in markov_chain:\n",
    "            markov_chain[current_word] = []\n",
    "        \n",
    "        markov_chain[current_word].append(next_word)\n",
    "    \n",
    "    return markov_chain\n",
    "\n",
    "# Option 2: Markov Chain with N-grams\n",
    "def build_markov_chain_ngrams(tokens, n=2):\n",
    "    markov_chain = {}\n",
    "    \n",
    "    for i in range(len(tokens) - n):\n",
    "        current_ngram = tuple(tokens[i:i + n])  # Take n words as a tuple\n",
    "        next_word = tokens[i + n]\n",
    "        \n",
    "        if current_ngram not in markov_chain:\n",
    "            markov_chain[current_ngram] = []\n",
    "        \n",
    "        markov_chain[current_ngram].append(next_word)\n",
    "    \n",
    "    return markov_chain\n",
    "\n",
    "# Option 3: Markov Chain with Weighted Transitions\n",
    "def build_markov_chain_weighted(tokens):\n",
    "    markov_chain = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for i in range(len(tokens) - 1):\n",
    "        current_word = tokens[i]\n",
    "        next_word = tokens[i + 1]\n",
    "        markov_chain[current_word][next_word] += 1  # Count occurrences\n",
    "    \n",
    "    return markov_chain\n",
    "\n",
    "# Step 3: Generating text with the Markov chain\n",
    "# Option 1: Generate text with standard Markov Chain (Unigrams)\n",
    "def generate_markov_text(chain, num_words):\n",
    "    # Start with a random word from the chain\n",
    "    current_word = random.choice(list(chain.keys()))\n",
    "    generated_text = [current_word]\n",
    "    \n",
    "    for _ in range(num_words - 1):\n",
    "        next_words = chain.get(current_word)\n",
    "        \n",
    "        if not next_words:\n",
    "            # If there are no next words, break early\n",
    "            break\n",
    "        \n",
    "        current_word = random.choice(next_words)\n",
    "        generated_text.append(current_word)\n",
    "    \n",
    "    return ' '.join(generated_text)\n",
    "\n",
    "# Option 2: Generate text with N-grams\n",
    "def generate_markov_text_ngrams(chain, num_words, n=2):\n",
    "    # Start with a random n-gram from the chain\n",
    "    current_ngram = random.choice(list(chain.keys()))\n",
    "    generated_text = list(current_ngram)\n",
    "    \n",
    "    for _ in range(num_words - n):\n",
    "        next_words = chain.get(current_ngram)\n",
    "        \n",
    "        if not next_words:\n",
    "            break\n",
    "        \n",
    "        next_word = random.choice(next_words)\n",
    "        generated_text.append(next_word)\n",
    "        \n",
    "        # Shift the n-gram window to the right\n",
    "        current_ngram = tuple(generated_text[-n:])\n",
    "    \n",
    "    return ' '.join(generated_text)\n",
    "\n",
    "# Option 3: Generate text with a custom starting word\n",
    "def generate_markov_text_with_start(chain, num_words, start_word=None):\n",
    "    if start_word and start_word in chain:\n",
    "        current_word = start_word\n",
    "    else:\n",
    "        current_word = random.choice(list(chain.keys()))\n",
    "    \n",
    "    generated_text = [current_word]\n",
    "    \n",
    "    for _ in range(num_words - 1):\n",
    "        next_words = chain.get(current_word)\n",
    "        \n",
    "        if not next_words:\n",
    "            break\n",
    "        \n",
    "        current_word = random.choice(next_words)\n",
    "        generated_text.append(current_word)\n",
    "    \n",
    "    return ' '.join(generated_text)\n",
    "\n",
    "# Option 4: Generate text with weighted transitions\n",
    "def weighted_choice(choices):\n",
    "    total = sum(choices.values())\n",
    "    rand_value = random.uniform(0, total)\n",
    "    cumulative = 0\n",
    "    for choice, weight in choices.items():\n",
    "        cumulative += weight\n",
    "        if cumulative > rand_value:\n",
    "            return choice\n",
    "\n",
    "def generate_markov_text_weighted(chain, num_words):\n",
    "    current_word = random.choice(list(chain.keys()))\n",
    "    generated_text = [current_word]\n",
    "    \n",
    "    for _ in range(num_words - 1):\n",
    "        next_words = chain.get(current_word)\n",
    "        \n",
    "        if not next_words:\n",
    "            break\n",
    "        \n",
    "        current_word = weighted_choice(next_words)\n",
    "        generated_text.append(current_word)\n",
    "    \n",
    "    return ' '.join(generated_text)\n",
    "\n",
    "# Example usage:\n",
    "text = \"Hello, world! How are you today? Hello, how is the world today?\"\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = tokenize(text)\n",
    "\n",
    "# 1. Standard Markov Chain (Unigrams)\n",
    "markov_chain = build_markov_chain(tokens)\n",
    "generated_text = generate_markov_text(markov_chain, 10)\n",
    "print(\"Generated text (unigrams): \", generated_text)\n",
    "\n",
    "# 2. Markov Chain with N-grams (bigrams)\n",
    "markov_chain_ngrams = build_markov_chain_ngrams(tokens, n=2)\n",
    "generated_text_ngrams = generate_markov_text_ngrams(markov_chain_ngrams, 10, n=2)\n",
    "print(\"Generated text (bigrams): \", generated_text_ngrams)\n",
    "\n",
    "# 3. Markov Chain with a custom starting word\n",
    "generated_text_with_start = generate_markov_text_with_start(markov_chain, 10, start_word=\"hello\")\n",
    "print(\"Generated text (with custom start): \", generated_text_with_start)\n",
    "\n",
    "# 4. Markov Chain with weighted transitions\n",
    "markov_chain_weighted = build_markov_chain_weighted(tokens)\n",
    "generated_text_weighted = generate_markov_text_weighted(markov_chain_weighted, 10)\n",
    "print(\"Generated text (weighted): \", generated_text_weighted)\n",
    "\n",
    "\n",
    "THE FIRST EXTENSION:\n",
    "1.Extension 1: Handling Punctuation and Case Sensitivity\n",
    "By default, the current version of the chatbot splits text based on spaces, which can cause punctuation marks to be attached to words. To improve this, we can remove punctuation and make the text lowercase so that it treats \"Hello\" and \"hello\" as the same word.\n",
    "\n",
    "import string\n",
    "\n",
    "# Tokenizer that removes punctuation and converts text to lowercase\n",
    "def tokenize(text):\n",
    "    # Remove punctuation using str.translate and convert to lowercase\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    return text.split()\n",
    "\n",
    "# Example usage with punctuation handling\n",
    "text = \"Hello, world! How are you today? Hello, how is the world today?\"\n",
    "tokens = tokenize(text)\n",
    "markov_chain = build_markov_chain(tokens)\n",
    "generated_text = generate_markov_text(markov_chain, 10)\n",
    "\n",
    "print(\"Generated text: \", generated_text)\n",
    "\n",
    "Explanation:\n",
    "str.translate(): This removes punctuation marks by replacing them with empty strings.\n",
    ".lower(): Converts all words to lowercase to avoid treating differently capitalized words as separate entities.\n",
    "    \n",
    "THE SECOND EXTENSION:\n",
    "2.Extension 2: N-grams for Better Context\n",
    "Instead of looking at just one word at a time (unigrams), we can extend the model to use n-grams (e.g., pairs of words or trigrams) to provide better context and make the generated text more coherent.\n",
    "\n",
    "def build_markov_chain_ngrams(tokens, n=2):\n",
    "    markov_chain = {}\n",
    "    \n",
    "    for i in range(len(tokens) - n):\n",
    "        current_ngram = tuple(tokens[i:i + n])  # Take n words as a tuple\n",
    "        next_word = tokens[i + n]\n",
    "        \n",
    "        if current_ngram not in markov_chain:\n",
    "            markov_chain[current_ngram] = []\n",
    "        \n",
    "        markov_chain[current_ngram].append(next_word)\n",
    "    \n",
    "    return markov_chain\n",
    "\n",
    "# Generating text with n-grams\n",
    "def generate_markov_text_ngrams(chain, num_words, n=2):\n",
    "    # Start with a random n-gram from the chain\n",
    "    current_ngram = random.choice(list(chain.keys()))\n",
    "    generated_text = list(current_ngram)\n",
    "    \n",
    "    for _ in range(num_words - n):\n",
    "        next_words = chain.get(current_ngram)\n",
    "        \n",
    "        if not next_words:\n",
    "            break\n",
    "        \n",
    "        next_word = random.choice(next_words)\n",
    "        generated_text.append(next_word)\n",
    "        \n",
    "        # Shift the n-gram window to the right\n",
    "        current_ngram = tuple(generated_text[-n:])\n",
    "    \n",
    "    return ' '.join(generated_text)\n",
    "\n",
    "# Example usage with bigrams (n=2)\n",
    "tokens = tokenize(text)\n",
    "markov_chain_ngrams = build_markov_chain_ngrams(tokens, n=2)\n",
    "generated_text_ngrams = generate_markov_text_ngrams(markov_chain_ngrams, 10, n=2)\n",
    "\n",
    "print(\"Generated text (bigrams): \", generated_text_ngrams)\n",
    "\n",
    "Explanation:\n",
    "N-grams: Instead of storing transitions for single words, we store transitions for sequences of n words (e.g., bigrams when n=2 or trigrams when n=3).\n",
    "Contextual Coherence: This improves the flow of the generated text because it considers more context when selecting the next word.\n",
    " \n",
    "5.3\n",
    "\n",
    "This extension of the Markovian chatbot code incorporates a dataset of characters (likely from a text dataset such as \"avatar\") and segments the word transitions by character. Here’s a detailed breakdown:\n",
    "\n",
    "Initialization:\n",
    "\n",
    "characters: This Counter object keeps track of the frequency of characters in the dataset, where characters are represented as strings with spaces replaced by periods and converted to uppercase.\n",
    "nested_dict: A lambda function to create deeply nested dictionaries using defaultdict. This is useful for managing complex data structures where the depth of the dictionary is not known in advance.\n",
    "Data Preparation:\n",
    "\n",
    "characters is created from the avatar.character column by converting it to uppercase, replacing spaces with periods, and counting occurrences of each character.\n",
    "Setting Up Data Structures:\n",
    "\n",
    "word_used2C: A nested dictionary to track occurrences of bigrams (two-word sequences) for each character.\n",
    "next_word2C: A nested dictionary to track the third word following each bigram, segmented by character.\n",
    "Processing the Words:\n",
    "\n",
    "The loop iterates through the list of words, stopping at the third-to-last word to handle bigrams and trigrams.\n",
    "Updating word_used2C:\n",
    "\n",
    "Checks if the current word is in characters, assigning it to the character variable if it is.\n",
    "Initializes the entry for the character in word_used2C if it doesn’t exist.\n",
    "Updates the count for the bigram (word + ' ' + words[i+1]) in word_used2C[character].\n",
    "Updating next_word2C:\n",
    "\n",
    "Initializes the entry for the character in next_word2C if it doesn’t exist.\n",
    "Initializes the entry for the bigram in next_word2C[character] if it doesn’t exist.\n",
    "Updates the count of the third word (words[i+2]) that follows the bigram in next_word2C[character][word + ' ' + words[i+1]].\n",
    "Example\n",
    "Given a list of words:\n",
    "\n",
    "words = [\"I\", \"love\", \"Python\", \"and\", \"I\", \"love\", \"coding\"]\n",
    "And assuming avatar.character contains character names such as \"I\", \"love\", \"Python\", etc., in the dataset, this code will create:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "{\n",
    "    \"I\": {\"I love\": 1, \"love Python\": 1},\n",
    "    \"love\": {\"love Python\": 1, \"Python and\": 1},\n",
    "    \"Python\": {\"Python and\": 1, \"and I\": 1},\n",
    "    \"and\": {\"and I\": 1, \"I love\": 1}\n",
    "}\n",
    "\n",
    "{\n",
    "    \"I\": {\"I love\": {\"Python\": 1}},\n",
    "    \"love\": {\"love Python\": {\"and\": 1}},\n",
    "    \"Python\": {\"Python and\": {\"I\": 1}},\n",
    "    \"and\": {\"and I\": {\"love\": 1}}\n",
    "}\n",
    "Summary\n",
    "This code extends the Markovian model to segment the data by characters, allowing the creation of a character-based word transition model.\n",
    "This can be useful for generating text or predictions that are specific to each character or context within a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ca3ffa",
   "metadata": {},
   "source": [
    "#### 6. Report on your experience interacting with ChatBots to understand the Monte Hall problem and \"Markovian ChatBot\" code\n",
    "\n",
    "1. Discuss how quickly the ChatBot was able to be helpful for each of the above questions, and if so, how?<br><br>\n",
    "    \n",
    "2. Discuss whether or not interacting with ChatBot to try to figure things out was frustrating or unhelpful, and if so, how?<br><br>\n",
    "    \n",
    "3. Based on your experiences to date (e.g., including using ChatBots to troubleshoot coding errors in the previous homework), provide an overall assessment evaluating the usefulness of ChatBots as tools to help you understand code<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55928d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "6.1\n",
    "Response Speed:\n",
    "\n",
    "The ChatBot was fast in handling both types of problems (Monte Hall and Markov chains).\n",
    "There were no significant delays in responses, and the content was delivered clearly and on time.\n",
    "Helpfulness:\n",
    "\n",
    "Monte Hall: The ChatBot helped refactor the code to be more readable and intuitive. It also explained the probability logic behind the simulation.\n",
    "Markov Chain: The ChatBot gave a deep dive into the Markov model, provided code extensions, and offered step-by-step explanations that made understanding and enhancing the code much easier.\n",
    "Readability & Explainability:\n",
    "\n",
    "The ChatBot helped streamline complex code into simpler, more readable forms, making it easier to understand and debug.\n",
    "It emphasized breaking down each part of the code and connecting concepts with real-world scenarios for better clarity.\n",
    "Suggestions for Improvements:\n",
    "\n",
    "For the Monte Hall problem, using list comprehensions and better handling of door selection were recommended.\n",
    "For the Markov chain, handling punctuation, improving text generation with N-grams, and weighted transitions were suggested.\n",
    "Conclusion:\n",
    "The ChatBot was extremely helpful in addressing both questions and provided significant improvements in readability and understanding. \n",
    "It effectively guided me through the Monte Hall problem and Markov chain concepts,\n",
    "offering useful code enhancements and thorough explanations that made learning these topics much more approachable.\n",
    "\n",
    "6.2\n",
    "It is not frustrating or unhelpful for me to interacte with chatBot.Moreover I believe this extremely useful for me to communicate \n",
    "with CHATgpt.Because I believe that the most essensial part of humanbeing is the ability to use tool,which is the biggest difference between\n",
    "mankind and animals.So I believe the experience was overwhelmingly positive. The ChatBot provided thoughtful responses that were helpful, \n",
    "and any minor frustrations (like processing detailed answers or deciding between multiple alternatives) were outweighed by the clarity\n",
    "and improvements it brought to both the Monte Hall problem and the Markov Chain code.\n",
    "\n",
    "6.3\n",
    "Strengths:\n",
    "Real-Time Feedback:\n",
    "\n",
    "Strength: Provides instant answers to coding questions, speeding up learning.\n",
    "Example: Quickly clarified the Monte Hall simulation logic and suggested improvements.\n",
    "Detailed Explanations:\n",
    "\n",
    "Strength: Breaks down complex concepts into easier-to-understand parts.\n",
    "Example: Explained the Markov Chain model in simple steps, making it more accessible.\n",
    "Code Improvement Suggestions:\n",
    "\n",
    "Strength: Offers advice on how to refactor and optimize code.\n",
    "Example: Suggested simplifying the Monte Hall loop and improving the Markov Chain code.\n",
    "Educational Guidance:\n",
    "\n",
    "Strength: Links theory to practice, enhancing overall understanding.\n",
    "Example: Explained the Monte Hall problem's logic and the role of N-grams in Markov Chains.\n",
    "Limitations:\n",
    "Overwhelming Detail:\n",
    "\n",
    "Limitation: Sometimes, explanations are too detailed, which can be confusing.\n",
    "Example: Detailed discussions on code extensions might be hard to digest.\n",
    "Context Sensitivity:\n",
    "\n",
    "Limitation: May not always fully understand specific issues or nuances.\n",
    "Example: General solutions might not fit unique or complex problems.\n",
    "Limited Interactive Debugging:\n",
    "\n",
    "Limitation: Cannot interactively debug or visualize code execution.\n",
    "Example: Suggestions are helpful, but real-time debugging or execution feedback is needed for more complex issues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98038d55",
   "metadata": {},
   "source": [
    "#### 7. Reflect on your experience interacting with ChatBot and describe how your perception of AI-driven assistance tools in the context of learning coding, statistics, and data science has been evolving (or not) since joining the course<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff0c650",
   "metadata": {},
   "outputs": [],
   "source": [
    "7.\n",
    "It is not frustrating or unhelpful for me to interacte with chatBot.Moreover I believe this extremely useful for me to communicate \n",
    "with CHATgpt.Because I believe that the most essensial part of humanbeing is the ability to use tool,which is the biggest difference between\n",
    "mankind and animals.So I believe the experience was overwhelmingly positive.\n",
    "However,when sometimes wo meet some special situations such as tests or examinations.It needs our own ability to complete all the risks by \n",
    "ourselves, so at that time, we can only use our knowledge which some of them is taughted by chatGPT to prove us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e716cc",
   "metadata": {},
   "source": [
    "#### 8. ChatBots consume text data available on the web or platforms, and thus represents a new way to \"search consensensus\" that condenses and summarizes mainstream human thought<br><br>\n",
    "\n",
    "1. Start a new ChatBot session and discuss the relevance of learning and adaptability, communication, coding, and statistics and data analysis as skills in the modern world, especially with respect to career opportunities (particularly in the context of the data science industry)<br><br>\n",
    "    \n",
    "2. See if ChatBot thinks you could be a statistician or data scientist without coding or doing data analysis, and then transition your ChatBot conversation into a career exploration discussion, using the ChatBot to identify the skills that might be the most valuable for a career that you're interested<br><br>\n",
    "    \n",
    "3. Ask for a summary of this ChatBot session and paste it into your homework notebook (including link(s) to chat log histories if you're using ChatBot)<br><br>\n",
    "    \n",
    "4. Paraphrase the assessments and conclusions of your conversation in the form of a reflection on your current thoughts regarding your potential future career(s) and how you can go about building the skills you need to pursue it<br><br>\n",
    "\n",
    "5. Give your thoughts regarding the helpfulness or limitations of your conversation with a ChatBot, and describe the next steps you would take to pursue this conversation further if you felt the information the ChatBot provides was somewhat high level and general, and perhaps lacked the depth and detailed knowledge of a dedicated subject matter expert who had really take the time to understand the ins and outs of the industry and career path in question.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bfd708",
   "metadata": {},
   "outputs": [],
   "source": [
    "8.1\n",
    "1. Learning and Adaptability\n",
    "Relevance: In a rapidly evolving field like data science, the ability to continuously learn and adapt is crucial. New tools, technologies, and methodologies emerge frequently, and staying updated is key to maintaining a competitive edge.\n",
    "Career Impact: Employers value individuals who can quickly adapt to new challenges and technologies. Being a lifelong learner helps you remain relevant and innovative in your role.\n",
    "2. Communication\n",
    "Relevance: Effective communication is essential for translating complex data insights into understandable information for stakeholders. Data scientists must be able to present their findings clearly and persuasively.\n",
    "Career Impact: Strong communication skills can set you apart in the data science field. It enables you to work effectively with cross-functional teams, explain technical concepts to non-technical audiences, and drive data-driven decision-making.\n",
    "3. Coding\n",
    "Relevance: Coding is a fundamental skill in data science. Proficiency in programming languages like Python, R, or SQL is necessary for data manipulation, analysis, and building machine learning models.\n",
    "Career Impact: Coding skills are essential for performing data analysis, automating tasks, and developing algorithms. A strong coding background enhances your ability to handle complex datasets and implement data science solutions effectively.\n",
    "4. Statistics and Data Analysis\n",
    "Relevance: Statistics and data analysis form the backbone of data science. Understanding statistical methods and data analysis techniques is crucial for drawing accurate conclusions and making informed decisions based on data.\n",
    "Career Impact: Mastery of statistics and data analysis is often a key requirement for data science roles. It allows you to interpret data correctly, validate models, and provide actionable insights that drive business strategy.\n",
    "Overall Impact in Data Science Careers\n",
    "Learning and Adaptability: Keeps you up-to-date with industry trends and evolving technologies.\n",
    "Communication: Facilitates effective collaboration and helps in conveying insights to stakeholders.\n",
    "Coding: Enables you to work with data, develop models, and solve complex problems.\n",
    "Statistics and Data Analysis: Ensures robust analysis and accurate interpretation of data.\n",
    "In summary, these skills are interrelated and collectively crucial for success in the data science industry. They enable you to tackle challenges, innovate, and contribute effectively to data-driven decision-making processes.\n",
    "\n",
    "8.2\n",
    "Can You Be a Statistician or Data Scientist Without Coding or Data Analysis?\n",
    "Statistician:\n",
    "\n",
    "Coding: While it’s possible to have some roles in statistics that are less focused on coding, most modern statisticians use programming to handle data, perform complex analyses, and implement statistical models. Skills in languages like R or Python are generally highly valued.\n",
    "Data Analysis: This is a core part of being a statistician. Analyzing data, applying statistical methods, and interpreting results are fundamental tasks. Without these skills, it would be challenging to perform the role effectively.\n",
    "Data Scientist:\n",
    "\n",
    "Coding: Coding is a fundamental skill for data scientists. They use programming to manipulate data, build algorithms, and develop machine learning models. Lack of coding skills would significantly limit your ability to work with data and develop insights.\n",
    "Data Analysis: Data analysis is at the heart of data science. Data scientists need to understand and apply various analytical techniques to extract meaningful information from data. Without data analysis skills, it would be difficult to fulfill the role’s responsibilities.\n",
    "In summary, while there might be some niche roles or supporting positions where coding and in-depth data analysis are less central, most positions for statisticians and data scientists require strong skills in both areas.\n",
    "\n",
    "Can You Be a Statistician or Data Scientist Without Coding or Data Analysis?\n",
    "Statistician:\n",
    "\n",
    "Coding: While it’s possible to have some roles in statistics that are less focused on coding, most modern statisticians use programming to handle data, perform complex analyses, and implement statistical models. Skills in languages like R or Python are generally highly valued.\n",
    "Data Analysis: This is a core part of being a statistician. Analyzing data, applying statistical methods, and interpreting results are fundamental tasks. Without these skills, it would be challenging to perform the role effectively.\n",
    "Data Scientist:\n",
    "\n",
    "Coding: Coding is a fundamental skill for data scientists. They use programming to manipulate data, build algorithms, and develop machine learning models. Lack of coding skills would significantly limit your ability to work with data and develop insights.\n",
    "Data Analysis: Data analysis is at the heart of data science. Data scientists need to understand and apply various analytical techniques to extract meaningful information from data. Without data analysis skills, it would be difficult to fulfill the role’s responsibilities.\n",
    "In summary, while there might be some niche roles or supporting positions where coding and in-depth data analysis are less central, most positions for statisticians and data scientists require strong skills in both areas.\n",
    "\n",
    "8.3\n",
    "https://chatgpt.com/share/66e5c3b6-bc10-8003-90a9-0aed5e75c806\n",
    "\n",
    "8.4\n",
    "In the near future, there will have a period of time that AI chatBot might replace the most of work in our daily life.Including the abilities\n",
    "to write program, take care of the specific items, the guard of some public places, the workers in the mobile phone factories will witness an\n",
    "incredible situation that all their works can be replaced by some robots or some fantastic facilities.So in this kind of society, I believe the \n",
    "key point to win our own future is to maintain our innovative mind and the power to get the assistant of AI tools.\n",
    "\n",
    "From my point of view, I will try my best to dive into the carrer to improve the artificial intellengence to seek my fortune in my life time.\n",
    "\n",
    "\n",
    "\n",
    "8.5\n",
    "My opinion about chatGPT:It is not frustrating or unhelpful for me to interacte with chatBot.Moreover I believe this extremely useful for me to communicate \n",
    "with CHATgpt.Because I believe that the most essensial part of humanbeing is the ability to use tool,which is the biggest difference between\n",
    "mankind and animals.So I believe the experience was overwhelmingly positive.\n",
    "However,when sometimes wo meet some special situations such as tests or examinations.It needs our own ability to complete all the risks by \n",
    "ourselves, so at that time, we can only use our knowledge which some of them is taughted by chatGPT to prove us.\n",
    "\n",
    "Next Steps for Further Pursuit\n",
    "1.Seek Expert Advice:\n",
    "Mentorship: Connect with industry professionals or mentors who have extensive experience in data science or statistics. They can provide detailed insights and personal experiences that go beyond general information.\n",
    "Industry Events: Attend conferences, webinars, or workshops to hear from experts and gain exposure to the latest trends and practices in the field.\n",
    "In-Depth Research:\n",
    "\n",
    "2.Advanced Learning: Explore advanced courses, workshops, or certifications that focus on specific areas of interest within data science or statistics. This will help deepen my understanding of specialized topics.\n",
    "Case Studies and Projects: Study real-world case studies and engage in complex projects to gain practical experience and understand industry applications.\n",
    "Networking:\n",
    "\n",
    "3.Professional Networks: Join professional organizations or online communities related to data science or statistics. Engaging with these networks can provide valuable insights and opportunities for learning from peers.\n",
    "Informational Interviews: Conduct informational interviews with professionals in the field to gather detailed information about their career paths, challenges, and industry-specific skills.\n",
    "Hands-On Experience:\n",
    "\n",
    "4.Internships and Projects: Pursue internships or freelance projects to gain hands-on experience and apply theoretical knowledge in practical settings. This will also help in building a portfolio that showcases relevant skills."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49542c1",
   "metadata": {},
   "source": [
    "#### 9. Have you reviewed the course [wiki-textbook](https://github.com/pointOfive/stat130chat130/wiki) and interacted with a ChatBot (or, if that wasn't sufficient, real people in the course piazza discussion board or TA office hours) to help you understand all the material in the tutorial and lecture that you didn't quite follow when you first saw it?<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3319ac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yep! The chatBot has explained the course tasks carefully for me.Even the Monty Hall problem which is difficult for me in the tutorial class\n",
    "is easy for me with the help of chatGPT. I am so glad that it will give me tons of new ideas and plenty of examples and explains.\n",
    "I believe that I can learn a lot with ChatBot in the near future!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f93f58f",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/66e5c3b6-bc10-8003-90a9-0aed5e75c806\n",
    "the link is the chatGPT website that I used in the homework."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
